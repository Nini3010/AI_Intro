{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9Y5vQ9eVboeY/ry7QYoR5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"SbetBT1XNpyZ","executionInfo":{"status":"ok","timestamp":1734617337656,"user_tz":-60,"elapsed":216,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}}},"outputs":[],"source":["# keras imports for the dataset and building our neural network\n","import os\n","from datetime import datetime\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# from keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","from matplotlib.gridspec import GridSpec\n","from sklearn.metrics import (\n","    ConfusionMatrixDisplay,\n","    classification_report,\n","    confusion_matrix,\n",")\n","from tensorflow.keras import callbacks\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import (\n","    BatchNormalization,\n","    Conv2D,\n","    Dense,\n","    Dropout,\n","    Flatten,\n","    MaxPool2D,\n",")\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers import SGD, Adam\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","\n","\n"]},{"cell_type":"code","source":["def display_classification_report(\n","    classification_report, figure_path, figure_name, onscreen=True\n","):\n","    f = open(os.path.join(figure_path, figure_name + \".txt\"), \"w\")\n","    f.write(classification_report)\n","    f.close()\n","\n","    if onscreen:\n","        print(classification_report)"],"metadata":{"id":"LpLvp5LbHJ3F","executionInfo":{"status":"ok","timestamp":1734615212454,"user_tz":-60,"elapsed":361,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def display_confusion_matrix(\n","    confusion_matrix, labels, figure_path, figure_name, figure_format, onscreen=True\n","):\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n","\n","    disp.plot(cmap=plt.cm.Greys)\n","    fig = disp.figure()\n","\n","    plt.savefig(\n","        os.path.join(figure_path, figure_name + \".\" + figure_format),\n","        format=figure_format,\n","    )\n","\n","    if onscreen:\n","        print(\"Show confusion matrix on display\")\n","        plt.show()\n","    else:\n","        plt.close(fig)\n","\n","\n","def display_activations(\n","    input,\n","    label,\n","    activations,\n","    layer_names,\n","    figure_path,\n","    figure_name,\n","    figure_format,\n","    onscreen=True,\n","):\n","    fig = plt.figure(layout=\"constrained\", figsize=(10, 8))\n","    subfigs = fig.subfigures(\n","        1, len(activations) + 1\n","    )  # layers + input , figsize=(row_size*2.5,len(model.layers)*1.5))\n","\n","    subfigs[0].subplots(1, 1)\n","    subfigs[0].suptitle(\"Label: {}\".format(label))\n","    axs = subfigs[0].get_axes()\n","    axs[0].set_xticks([])\n","    axs[0].set_yticks([])\n","    axs[0].imshow(input, cmap=\"gray_r\")\n","\n","    for layer_index in range(0, len(activations)):\n","        print(\"layer:\" + str(layer_index))\n","        print(activations[layer_index].shape[-1])\n","        subfigs[layer_index + 1].suptitle(layer_names[layer_index])\n","        subfigs[layer_index + 1].subplots(activations[layer_index].shape[-1], 1)\n","\n","    for layer_index in range(0, len(activations)):\n","        print(activations[layer_index].shape)\n","        # range(0,activations.shape[-1]):\n","        axs = subfigs[layer_index + 1].get_axes()\n","        for plane_index in range(0, activations[layer_index].shape[-1]):\n","            plane = activations[layer_index][0, :, :, plane_index]\n","            # activations -= activations.mean()\n","            # activations /= activations.std()\n","            # activations *= 64\n","            # activations += 128\n","            # activations = np.clip(activations, 0, 255).astype('uint8')\n","            # axs[plane_index].imshow(model.layers[layer_index].output[0, :, :, plane_index], cmap='gray')\n","            axs[plane_index].set_xticks([])\n","            axs[plane_index].set_yticks([])\n","            axs[plane_index].imshow(plane, cmap=\"gray_r\")\n","\n","    fig.savefig(\n","        os.path.join(figure_path, figure_name + \".\" + figure_format),\n","        format=figure_format,\n","    )\n","    if onscreen:\n","        print(\"Show activations on display\")\n","        plt.show()\n","    else:\n","        plt.close(fig)\n","\n","\n","def display_weights_column(\n","    weights, layer_names, figure_path, figure_name, figure_format, onscreen=True\n","):\n","    n_layers_with_weights = 0\n","    for layer_index in range(0, len(weights)):\n","        layer_weights = weights[layer_index]\n","        if len(layer_weights) > 0:\n","            n_layers_with_weights += 1\n","\n","    fig = plt.figure(layout=\"constrained\", figsize=(30, 15), frameon=False)\n","    # fig.tight_layout()\n","    plt.subplots_adjust(top=0.1, bottom=0.1, hspace=0.1, wspace=0.1)\n","    subfigs = fig.subfigures(1, n_layers_with_weights)\n","    layer_index_with_weights = 0\n","    print(\"Number of layers: \" + str(len(weights)))\n","    for layer_index in range(0, len(weights)):\n","        layer_weights = weights[layer_index]\n","\n","        print(\"layer:\" + str(layer_index))\n","        # only weights (0) no biases (1)\n","        # print(len(layer_weights[0]))\n","        # print(weights[layer_index])\n","        # for i in range(0,len(weights[layer_index])):\n","        # subfigs[layer_index+1].suptitle(layer_names[layer_index])\n","        # only weights no biases\n","        if len(layer_weights) > 0 and len(layer_weights[0].shape) > 1:\n","            print(\" weights shape \", layer_weights[0].shape)\n","\n","            # subfigs[layer_index_with_weights].suptitle(layer_names[layer_index])\n","            # subfigs[layer_index_with_weights].tight_layout()\n","            # squeeze=False squeezing at all is done: the returned Axes object is always a 2D array containing\n","            axs = subfigs[layer_index_with_weights].subplots(\n","                layer_weights[0].shape[-2], layer_weights[0].shape[-1], squeeze=False\n","            )  # , sharex=True, sharey=True)\n","            subfigs[layer_index_with_weights].subplots_adjust(\n","                wspace=0.001, hspace=0.0, top=0.0, bottom=0.0, left=0.0, right=0.0\n","            )\n","            print(axs.shape)\n","            for i in range(0, layer_weights[0].shape[-2]):\n","                for j in range(0, layer_weights[0].shape[-1]):\n","                    # print(i,j)\n","                    w = layer_weights[0]\n","                    # print(w[:,:,i,j])\n","                    axs[i, j].imshow(\n","                        w[:, :, i, j], cmap=\"gray_r\", interpolation=\"nearest\"\n","                    )\n","                    axs[i, j].axis(\"off\")\n","                    # axs[i,j].set_xticks([])\n","                    # axs[i,j].set_yticks([])\n","                    # axs[i,j].imshow(w[:,:,i,j], cmap='gray_r', interpolation='nearest')\n","\n","            layer_index_with_weights += 1\n","    fig.savefig(\n","        os.path.join(figure_path, figure_name + \".\" + figure_format),\n","        format=figure_format,\n","    )\n","\n","    if onscreen:\n","        print(\"Show weights on display\")\n","        plt.show()\n","    else:\n","        plt.close(fig)\n","\n","\n","def display_loss_function(\n","    history, figure_path, figure_name, figure_format, onscreen=True\n","):\n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","    epochs = range(1, len(loss) + 1)\n","    fig = plt.figure()\n","    plt.plot(epochs, loss, color=\"red\", label=\"Training loss\")\n","    plt.plot(epochs, val_loss, color=\"green\", label=\"Validation loss\")\n","    plt.title(\"Training loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    fig.savefig(\n","        os.path.join(figure_path, figure_name + \".\" + figure_format),\n","        format=figure_format,\n","    )\n","    if onscreen:\n","        print(\"Show loss on display\")\n","        plt.show()\n","    else:\n","        plt.close(fig)"],"metadata":{"id":"h_h5f0srHgb9","executionInfo":{"status":"ok","timestamp":1734615213562,"user_tz":-60,"elapsed":243,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# loading the dataset\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","# let's print the shape of the dataset\n","\n","# building the input vector from the 28x28 pixels\n","X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","X_train = X_train.astype(\"float32\")\n","X_test = X_test.astype(\"float32\")\n","\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)\n","\n","\n","# normalizing the data\n","X_train /= 255\n","X_test /= 255\n","\n","# one-hot encoding using keras' numpy-related utilities\n","n_classes = 10\n","print(\"Shape before one-hot encoding: \", y_train.shape)\n","Y_train = to_categorical(y_train, n_classes)\n","Y_test = to_categorical(y_test, n_classes)\n","print(\"Shape after one-hot encoding: \", Y_train.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOdmzGqEHk3e","executionInfo":{"status":"ok","timestamp":1734615256074,"user_tz":-60,"elapsed":834,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}},"outputId":"d49f12d8-daf6-456c-e6b0-1812c7cc789b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","X_train shape (60000, 28, 28, 1)\n","y_train shape (60000,)\n","X_test shape (10000, 28, 28, 1)\n","y_test shape (10000,)\n","Shape before one-hot encoding:  (60000,)\n","Shape after one-hot encoding:  (60000, 10)\n"]}]},{"cell_type":"code","source":["n_cnn1planes = 15\n","n_cnn1kernel = 3\n","n_poolsize = 1\n","\n","\n","# Stride defines the step size at which the filter moves across the input during convolution.\n","# A larger stride results in a reduction of the spatial dimensions of the output feature map.\n","# Stride can be adjusted to control the level of downsampling in the network.\n","# Stride is a critical parameter for controlling the spatial resolution of the feature maps and influencing the receptive field of the network.\n","n_strides = 1\n","n_dense = 100\n","dropout = 0.3\n","\n","n_epochs = 10\n","\n","model_name = (\n","    \"CNN_Handwritten_OCR_CNN\"\n","    + str(n_cnn1planes)\n","    + \"_KERNEL\"\n","    + str(n_cnn1kernel)\n","    + \"_Epochs\"\n","    + str(n_epochs)\n",")\n","# figure_format='svg'\n","figure_format = \"png\"\n","figure_path = \"./\"\n","log_path = \"./log\"\n","\n","# layer_outputs = [layer.output for layer in model.layers[1:7]]\n","# activation_model = Model(inputs=model.input,outputs=layer_outputs)\n","\n","# building a linear stack of layers with the sequential model\n","model = Sequential()\n","# convolutional layer\n","cnn1 = Conv2D(\n","    n_cnn1planes,\n","    kernel_size=(n_cnn1kernel, n_cnn1kernel),\n","    strides=(n_strides, n_strides),\n","    padding=\"valid\",\n","    activation=\"relu\",\n","    input_shape=(28, 28, 1),\n",")\n","model.add(cnn1)\n","model.add(MaxPool2D(pool_size=(n_poolsize, n_poolsize)))\n","\n","# model.add(Dropout(dropout))\n","\n","cnn2 = Conv2D(\n","    n_cnn1planes * 2,\n","    kernel_size=(n_cnn1kernel, n_cnn1kernel),\n","    strides=(n_strides, n_strides),\n","    padding=\"valid\",\n","    activation=\"relu\",\n",")\n","model.add(cnn2)\n","model.add(MaxPool2D(pool_size=(n_poolsize, n_poolsize)))\n","\n","# model.add(Dropout(dropout))\n","\n","cnn3 = Conv2D(\n","    n_cnn1planes * 4,\n","    kernel_size=(n_cnn1kernel, n_cnn1kernel),\n","    strides=(n_strides, n_strides),\n","    padding=\"valid\",\n","    activation=\"relu\",\n",")\n","model.add(cnn3)\n","model.add(MaxPool2D(pool_size=(n_poolsize, n_poolsize)))\n","\n","# model.add(Dropout(dropout))\n","\n","# flatten output of conv\n","model.add(Flatten())\n","\n","\n","model.add(Dropout(dropout))\n","\n","# hidden layer\n","model.add(Dense(n_dense, activation=\"relu\"))\n","# output layer\n","model.add(Dense(n_classes, activation=\"softmax\"))\n","\n","# compiling the sequential model\n","\n","model_name += \"_Optimzer_\" + \"SGD\"\n","\n","# vary the constant learning rate\n","model_name += \"_LearningRate_\" + \"Constant\"\n","learning_rate = 0.001\n","\n","# OR use a learning rate scheduler that adapts the learning rate over the epochs of the training process\n","# https://keras.io/2.15/api/optimizers/learning_rate_schedules/\n","\n","# model_name += '_LearningRate_' + 'ExponentialDecay'\n","# learning_rate = ExponentialDecay(initial_learning_rate=1e-2, decay_steps=n_epochs, decay_rate=0.9)\n","\n","# learning_rate=0.01\n","momentum = 0.9\n","optimizer = SGD(learning_rate=learning_rate, momentum=momentum)\n","\n","# optimizer=Adam(learning_rate = learning_rate)\n","\n","\n","# vary the constant learning rate\n","# learning_rate = 0.01\n","# optimizer=SGD(learning_rate=learning_rate)\n","\n","model.compile(\n","    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer\n",")\n","\n","\n","layer_names = [layer.name for layer in model.layers[:8]]\n","\n","weights = [layer.get_weights() for layer in model.layers[:4]]\n","figure_name = model_name + \"_initial_weights\"\n","display_weights_column(weights, layer_names, \"./\", figure_name, figure_format, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kvy4mappIE-V","executionInfo":{"status":"ok","timestamp":1734615422861,"user_tz":-60,"elapsed":31349,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}},"outputId":"229e08a1-3f6d-4999-d880-fe346e833105"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","<ipython-input-4-2d6111f7471d>:87: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n","  plt.subplots_adjust(top=0.1, bottom=0.1, hspace=0.1, wspace=0.1)\n"]},{"output_type":"stream","name":"stdout","text":["Number of layers: 4\n","layer:0\n"," weights shape  (3, 3, 1, 15)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-2d6111f7471d>:110: UserWarning: This figure was using a layout engine that is incompatible with subplots_adjust and/or tight_layout; not calling subplots_adjust.\n","  subfigs[layer_index_with_weights].subplots_adjust(\n"]},{"output_type":"stream","name":"stdout","text":["(1, 15)\n","layer:1\n","layer:2\n"," weights shape  (3, 3, 15, 30)\n","(15, 30)\n","layer:3\n"]}]},{"cell_type":"code","source":["# training the model for n_epochs, use 10% of the training data as validation data\n","history = model.fit(\n","    X_train,\n","    Y_train,\n","    validation_split=0.1,\n","    batch_size=128,\n","    epochs=n_epochs,\n","    #callbacks=[callbacks.TensorBoard()],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":664},"id":"IUuW8SUpId7q","executionInfo":{"status":"error","timestamp":1734617273967,"user_tz":-60,"elapsed":322707,"user":{"displayName":"Nini 3010","userId":"10372903393944129204"}},"outputId":"eb832532-080a-404c-d23a-208afec71861"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 529ms/step - accuracy: 0.6206 - loss: 1.1815 - val_accuracy: 0.9253 - val_loss: 0.2382\n","Epoch 2/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 515ms/step - accuracy: 0.9179 - loss: 0.2717 - val_accuracy: 0.9598 - val_loss: 0.1474\n","Epoch 3/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 505ms/step - accuracy: 0.9401 - loss: 0.2013 - val_accuracy: 0.9663 - val_loss: 0.1225\n","Epoch 4/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 518ms/step - accuracy: 0.9527 - loss: 0.1574 - val_accuracy: 0.9708 - val_loss: 0.1042\n","Epoch 5/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 513ms/step - accuracy: 0.9596 - loss: 0.1378 - val_accuracy: 0.9750 - val_loss: 0.0907\n","Epoch 6/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 526ms/step - accuracy: 0.9676 - loss: 0.1070 - val_accuracy: 0.9778 - val_loss: 0.0857\n","Epoch 7/10\n","\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 519ms/step - accuracy: 0.9702 - loss: 0.0980 - val_accuracy: 0.9793 - val_loss: 0.0802\n","Epoch 8/10\n","\u001b[1m 70/422\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:51\u001b[0m 488ms/step - accuracy: 0.9734 - loss: 0.0862"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-e663c57abf06>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training the model for n_epochs, use 10% of the training data as validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["figure_name = model_name + \"_loss\"\n","display_loss_function(history, \"./\", figure_name, figure_format)\n","\n","\n","weights = [layer.get_weights() for layer in model.layers[:4]]\n","figure_name = model_name + \"_weights\"\n","display_weights_column(weights, layer_names, \"./\", figure_name, figure_format, False)\n","\n","X_test_images = X_test[:2]\n","for i in range(X_test_images.shape[0]):\n","    Y_test_pred = model.predict(np.expand_dims(X_test[i], axis=0))\n","    # ax.set_title('Label: {}'.format(np.argmax(Y_test[i])))\n","\n","    activation_model = Model(\n","        inputs=model.inputs, outputs=[layer.output for layer in model.layers]\n","    )\n","    activations = activation_model.predict(np.expand_dims(X_test[i], axis=0))\n","\n","    figure_name = model_name + \"_activations_\" + \"test_image_\" + str(i)\n","    display_activations(\n","        X_test[i],\n","        np.argmax(Y_test[i]),\n","        activations[:4],\n","        layer_names[:4],\n","        figure_path,\n","        figure_name,\n","        figure_format,\n","    )\n","\n","y_test_pred = model.predict(X_test)\n","cm = confusion_matrix(\n","    y_test, np.argmax(y_test_pred, axis=1), labels=range(0, n_classes)\n",")\n","\n","figure_name = model_name + \"_confusion_matrix\"\n","display_confusion_matrix(\n","    cm, range(0, n_classes), figure_path, figure_name, figure_format\n",")\n","\n","figure_name = model_name + \"_classification_report\"\n","display_classification_report(\n","    classification_report(\n","        y_test,\n","        np.argmax(y_test_pred, axis=1),\n","        target_names=[str(c) for c in range(0, n_classes)],\n","        digits=4,\n","    ),\n","    figure_path,\n","    figure_name,\n",")\n","\n","figure_name = model_name + \"_model_summary\"\n","stringlist = []\n","model.summary(print_fn=lambda x: stringlist.append(x))\n","model_summary = \"\\n\".join(stringlist)\n","display_classification_report(model_summary, figure_path, figure_name)"],"metadata":{"id":"YeIPK06TIg8Q"},"execution_count":null,"outputs":[]}]}